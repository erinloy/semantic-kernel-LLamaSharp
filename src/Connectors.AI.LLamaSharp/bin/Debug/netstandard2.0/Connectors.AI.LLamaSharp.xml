<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Connectors.AI.LLamaSharp</name>
    </assembly>
    <members>
        <member name="T:Connectors.AI.LLamaSharp.ChatCompletion.HistoryTransform">
            <summary>
            Default HistoryTransform Patch
            </summary>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.HistoryTransform.HistoryToText(LLama.Common.ChatHistory)">
            <inheritdoc/>
        </member>
        <member name="T:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion">
            <summary>
            LLamaSharp ChatCompletion
            </summary>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion.#ctor(System.String)">
            <summary>
            Create LLamaSharpChatCompletion instance
            </summary>
            <param name="modelPath"></param>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion.CreateNewChat(System.String)">
            <inheritdoc/>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion.GetChatCompletionsAsync(Microsoft.SemanticKernel.AI.ChatCompletion.ChatHistory,Microsoft.SemanticKernel.AI.ChatCompletion.ChatRequestSettings,System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion.GetStreamingChatCompletionsAsync(Microsoft.SemanticKernel.AI.ChatCompletion.ChatHistory,Microsoft.SemanticKernel.AI.ChatCompletion.ChatRequestSettings,System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatCompletion.Dispose">
            <summary>
            Dispose LLamaModel
            </summary>
        </member>
        <member name="T:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatMessage">
            <summary>
            LLamaSharp Chat Message
            </summary>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatMessage.#ctor(Microsoft.SemanticKernel.AI.ChatCompletion.AuthorRole,System.String)">
            <inheritdoc/>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatResult.#ctor(System.Collections.Generic.IAsyncEnumerable{System.String})">
            <summary>
            
            </summary>
            <param name="stream"></param>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatResult.GetChatMessageAsync(System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.ChatCompletion.LLamaSharpChatResult.GetStreamingChatMessageAsync(System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="T:Connectors.AI.LLamaSharp.LLamaSharpExtension">
            <summary>
            LLamaSharp Extension
            </summary>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.LLamaSharpExtension.ToLLamaSharpChatHistory(Microsoft.SemanticKernel.AI.ChatCompletion.ChatHistory)">
            <summary>
            Convert ChatHistory to LLamaSharp ChatHistory
            </summary>
            <param name="chatHistory"></param>
            <returns></returns>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.LLamaSharpExtension.ToLLamaSharpInferenceParams(Microsoft.SemanticKernel.AI.ChatCompletion.ChatRequestSettings)">
            <summary>
            Convert ChatRequestSettings to LLamaSharp InferenceParams
            </summary>
            <param name="requestSettings"></param>
            <returns></returns>
        </member>
        <member name="M:Connectors.AI.LLamaSharp.LLamaSharpExtension.ToLLamaSharpInferenceParams(Microsoft.SemanticKernel.AI.TextCompletion.CompleteRequestSettings)">
            <summary>
            Convert CompleteRequestSettings to LLamaSharp InferenceParams
            </summary>
            <param name="requestSettings"></param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpTextCompletion">
            <summary>
            Text Completion use LLamaSharp
            </summary>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpTextCompletion.#ctor(System.String)">
            <summary>
            Create LLamaSharpTextCompletion Instance
            </summary>
            <param name="modelPath"></param>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpTextCompletion.Dispose">
            <summary>
            Dispose
            </summary>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpTextCompletion.GetCompletionsAsync(System.String,Microsoft.SemanticKernel.AI.TextCompletion.CompleteRequestSettings,System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpTextCompletion.GetStreamingCompletionsAsync(System.String,Microsoft.SemanticKernel.AI.TextCompletion.CompleteRequestSettings,System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpEmbeddingGeneration">
            <summary>
            IEmbeddingGeneration use LLamaSharp 
            </summary>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpEmbeddingGeneration.#ctor(System.String)">
            <summary>
            Create LLamaSharpEmbedding generation instance
            </summary>
            <param name="modelPath"></param>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpEmbeddingGeneration.GenerateEmbeddingsAsync(System.Collections.Generic.IList{System.String},System.Threading.CancellationToken)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.SemanticKernel.Connectors.AI.LLamaSharp.TextCompletion.LLamaSharpEmbeddingGeneration.Dispose">
            <inheritdoc/>
        </member>
    </members>
</doc>
